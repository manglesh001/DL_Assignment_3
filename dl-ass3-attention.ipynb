{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11871625,"sourceType":"datasetVersion","datasetId":7460569}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"  !pip install wandb\nimport wandb\n!wandb login 58a0b576fd5221cd0d63b154deaabbe535e853c6","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:25:37.406928Z","iopub.execute_input":"2025-05-19T18:25:37.407231Z","iopub.status.idle":"2025-05-19T18:25:46.963951Z","shell.execute_reply.started":"2025-05-19T18:25:37.407210Z","shell.execute_reply":"2025-05-19T18:25:46.963141Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# =======================\n# Imports and Sweep Config\n# =======================\n# =======================\n# Imports and Sweep Config\n# =======================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport wandb\nimport os\nimport math\n\nsweep_config = {\n    'method': 'bayes',\n    'metric': {\n        'name': 'val_loss',\n        'goal': 'minimize'\n    },\n    'parameters': {\n        'embedding_dim': {'values': [32,64,128,256]},\n        'hidden_dim': {'values': [32,64,128,256]},\n        'enc_layers': {'values': [1,2,3]},\n        'dec_layers': {'values': [1,2,3]},\n        'cell_type': {'values': ['GRU', 'LSTM', 'RNN']},\n        'dropout': {'values': [0.2,0.3,0.5]},\n        'epochs': {'values': [10,15]},\n        'beam_size': {'values': [1,3,5]},\n        'attention_type': {'values': ['dot', 'general', 'concat']},\n        'batch_size': {'values': [64,128,256]},\n        'learning_rate': {'values': [0.001,0.0005,0.0001]}\n    }\n}\n\n# =======================\n# Default Config\n# =======================\ndefault_config = {\n    'embedding_dim': 32,\n    'hidden_dim': 64,\n    'enc_layers': 1,\n    'dec_layers': 1,\n    'cell_type': 'LSTM',\n    'dropout': 0.2,\n    'epochs': 10,\n    'beam_size': 1,\n    'attention_type': 'general',\n    'batch_size': 64,\n    'learning_rate': 0.001\n}\n\n\n# =======================\n# Vocabulary\n# =======================\nclass Vocab:\n    def __init__(self):\n        self.char2idx = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2}\n        self.idx2char = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\"}\n        self.size = 3\n\n    def build(self, texts):\n        for text in texts:\n            for char in text:\n                if char not in self.char2idx:\n                    self.char2idx[char] = self.size\n                    self.idx2char[self.size] = char\n                    self.size += 1\n\n    def encode(self, text):\n        return [self.char2idx[c] for c in text]\n\n    def decode(self, idxs):\n        return ''.join([self.idx2char[i] for i in idxs if i > 2])\n\n# =======================\n# Dataset\n# =======================\nclass TransliterationDataset(Dataset):\n    def __init__(self, filepath, inp_vocab, out_vocab):\n        self.pairs = []\n        with open(filepath, encoding='utf-8') as f:\n            for line in f:\n                fields = line.strip().split('\\t')\n                if len(fields) < 2:\n                    continue\n                lat, dev = fields[0], fields[1]\n                self.pairs.append((lat, dev))\n        inp_vocab.build([p[0] for p in self.pairs])\n        out_vocab.build([p[1] for p in self.pairs])\n        self.inp_vocab = inp_vocab\n        self.out_vocab = out_vocab\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        lat, dev = self.pairs[idx]\n        x = self.inp_vocab.encode(lat)\n        y = [self.out_vocab.char2idx[\"<sos>\"]] + self.out_vocab.encode(dev) + [self.out_vocab.char2idx[\"<eos>\"]]\n        return torch.tensor(x), torch.tensor(y)\n\ndef collate_fn(batch):\n    x_batch, y_batch = zip(*batch)\n    x_lens = [len(x) for x in x_batch]\n    y_lens = [len(y) for y in y_batch]\n    x_pad = nn.utils.rnn.pad_sequence(x_batch, batch_first=True, padding_value=0)\n    y_pad = nn.utils.rnn.pad_sequence(y_batch, batch_first=True, padding_value=0)\n    return x_pad, y_pad, torch.tensor(x_lens), torch.tensor(y_lens)\n\n# =======================\n# Attention Mechanism\n# =======================\nclass Attention(nn.Module):\n    def __init__(self, hidden_dim, attention_type='general'):\n        super().__init__()\n        self.attention_type = attention_type\n        \n        if attention_type == 'general':\n            self.attn = nn.Linear(hidden_dim, hidden_dim)\n        elif attention_type == 'concat':\n            self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n            self.v = nn.Linear(hidden_dim, 1, bias=False)\n            \n    def forward(self, hidden, encoder_outputs, mask=None):\n        # hidden: [batch_size, hidden_dim]\n        # encoder_outputs: [batch_size, src_len, hidden_dim]\n        \n        batch_size, src_len, hidden_dim = encoder_outputs.shape\n        \n        # For dot and general attention\n        if self.attention_type == 'dot':\n            # Calculate dot product between hidden and encoder_outputs\n            energy = torch.bmm(encoder_outputs, hidden.unsqueeze(2)).squeeze(2)\n            # energy: [batch_size, src_len]\n            \n        elif self.attention_type == 'general':\n            # Calculate general attention\n            energy = torch.bmm(encoder_outputs, self.attn(hidden).unsqueeze(2)).squeeze(2)\n            # energy: [batch_size, src_len]\n            \n        elif self.attention_type == 'concat':\n            # Repeat hidden across source length\n            hidden_expanded = hidden.unsqueeze(1).repeat(1, src_len, 1)\n            # Concatenate hidden and encoder_outputs\n            energy = self.v(torch.tanh(self.attn(torch.cat((hidden_expanded, encoder_outputs), dim=2)))).squeeze(2)\n            # energy: [batch_size, src_len]\n        \n        # Apply mask if provided (for padding)\n        if mask is not None:\n            energy = energy.masked_fill(mask == 0, -1e10)\n        \n        # Apply softmax to get attention weights\n        attention_weights = F.softmax(energy, dim=1)\n        # attention_weights: [batch_size, src_len]\n        \n        # Apply attention weights to encoder outputs\n        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n        # context: [batch_size, hidden_dim]\n        \n        return context, attention_weights\n\n# =======================\n# Encoder and Decoder\n# =======================\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers, cell_type, dropout):\n        super().__init__()\n        self.cell_type = cell_type\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        \n        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        rnn_class = {\"GRU\": nn.GRU, \"LSTM\": nn.LSTM, \"RNN\": nn.RNN}[cell_type]\n        self.rnn = rnn_class(emb_dim, hidden_dim, num_layers, batch_first=True, bidirectional=False, dropout=dropout if num_layers > 1 else 0)\n\n    def forward(self, x, lengths):\n        embedded = self.embedding(x)\n        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n        outputs, hidden = self.rnn(packed)\n        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n        \n        return outputs, hidden\n\nclass AttentionDecoder(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers, cell_type, dropout, attention_type):\n        super().__init__()\n        self.cell_type = cell_type\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        \n        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        rnn_class = {\"GRU\": nn.GRU, \"LSTM\": nn.LSTM, \"RNN\": nn.RNN}[cell_type]\n        \n        # Input to RNN will be embedding + context vector\n        self.rnn = rnn_class(emb_dim + hidden_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n        \n        self.attention = Attention(hidden_dim, attention_type)\n        \n        # Output layer combines hidden state and context vector\n        self.out = nn.Linear(hidden_dim * 2, vocab_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input_token, hidden, encoder_outputs, mask=None):\n        # input_token: [batch_size]\n        # hidden: tuple of [num_layers, batch_size, hidden_dim] for LSTM or [num_layers, batch_size, hidden_dim] for GRU/RNN\n        # encoder_outputs: [batch_size, src_len, hidden_dim]\n        \n        # Get the last layer's hidden state for attention\n        if self.cell_type == \"LSTM\":\n            attn_hidden = hidden[0][-1]  # Last layer's hidden state\n        else:\n            attn_hidden = hidden[-1]  # Last layer's hidden state\n        \n        # Calculate attention\n        context, attention_weights = self.attention(attn_hidden, encoder_outputs, mask)\n        \n        # Embed input token\n        embedded = self.embedding(input_token)  # [batch_size, emb_dim]\n        \n        # Concatenate embedding and context vector\n        rnn_input = torch.cat((embedded, context), dim=1).unsqueeze(1)  # [batch_size, 1, emb_dim + hidden_dim]\n        \n        # Pass through RNN\n        output, hidden = self.rnn(rnn_input, hidden)\n        \n        # Get the output from the last layer\n        if self.cell_type == \"LSTM\":\n            output_hidden = hidden[0][-1]  # Last layer's hidden state\n        else:\n            output_hidden = hidden[-1]  # Last layer's hidden state\n        \n        # Concatenate output and context for prediction\n        output = torch.cat((output_hidden, context), dim=1)\n        \n        # Apply dropout and predict\n        output = self.dropout(output)\n        prediction = self.out(output)\n        \n        return prediction, hidden, attention_weights\n\n# =======================\n# Seq2Seq Model with Beam Search\n# =======================\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, enc_layers, dec_layers, cell_type, device, beam_size=1):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.cell_type = cell_type\n        self.enc_layers = enc_layers\n        self.dec_layers = dec_layers\n        self.device = device\n        self.beam_size = beam_size\n\n    def create_mask(self, src, src_lens):\n        # Create mask for attention (1 for valid positions, 0 for padding)\n        batch_size = src.size(0)\n        max_len = src.size(1)\n        mask = torch.zeros(batch_size, max_len, device=self.device)\n        for i, length in enumerate(src_lens):\n            mask[i, :length] = 1\n        return mask\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        src_data, src_lens = src\n        batch_size, trg_len = trg.size()\n        vocab_size = self.decoder.out.out_features\n        \n        # Store outputs, attention weights\n        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n        attentions = torch.zeros(batch_size, trg_len, src_data.size(1)).to(self.device)\n        \n        # Encode\n        encoder_outputs, enc_hidden = self.encoder(src_data, src_lens)\n        \n        # Create mask for attention\n        mask = self.create_mask(src_data, src_lens)\n        \n        # Match encoder and decoder layers\n        if self.cell_type == \"LSTM\":\n            h, c = enc_hidden\n            h = self._match_layers(h)\n            c = self._match_layers(c)\n            dec_hidden = (h, c)\n        else:\n            dec_hidden = self._match_layers(enc_hidden)\n        \n        # First input to the decoder is the <sos> token\n        input_token = trg[:, 0]\n        \n        for t in range(1, trg_len):\n            output, dec_hidden, attn_weights = self.decoder(\n                input_token, dec_hidden, encoder_outputs, mask\n            )\n            \n            outputs[:, t] = output\n            attentions[:, t] = attn_weights\n            \n            # Teacher forcing\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input_token = trg[:, t] if teacher_force else top1\n            \n        return outputs, attentions\n\n    def _match_layers(self, hidden):\n        # Match encoder and decoder layers\n        if self.enc_layers == self.dec_layers:\n            return hidden\n        elif self.enc_layers > self.dec_layers:\n            return hidden[:self.dec_layers]\n        else:\n            pad = hidden.new_zeros((self.dec_layers - self.enc_layers, *hidden.shape[1:]))\n            return torch.cat([hidden, pad], dim=0)\n    \n    def beam_search(self, src, max_len=50, sos_idx=1, eos_idx=2):\n        src_data, src_lens = src\n        batch_size = src_data.size(0)\n        assert batch_size == 1, \"Beam search only supports batch size of 1 for now\"\n\n        # Encode\n        encoder_outputs, enc_hidden = self.encoder(src_data, src_lens)\n        mask = self.create_mask(src_data, src_lens)\n\n        # Prepare initial hidden state\n        if self.cell_type == \"LSTM\":\n            h, c = enc_hidden\n            h = self._match_layers(h)\n            c = self._match_layers(c)\n            dec_hidden = (h, c)\n        else:\n            dec_hidden = self._match_layers(enc_hidden)\n\n        # Initialize beams with [score, sequence, hidden_state]\n        beams = [{\n            \"score\": 0.0,\n            \"seq\": [sos_idx],\n            \"hidden\": dec_hidden\n        }]\n\n        for _ in range(max_len):\n            new_beams = []\n            for beam in beams:\n                seq = beam[\"seq\"]\n                if seq[-1] == eos_idx:\n                    new_beams.append(beam)\n                    continue\n\n                input_token = torch.tensor([seq[-1]], device=self.device)\n                dec_hidden = beam[\"hidden\"]\n                output, new_hidden, _ = self.decoder(input_token, dec_hidden, encoder_outputs, mask)\n\n                log_probs = F.log_softmax(output, dim=1).squeeze(0)\n                topk_log_probs, topk_indices = torch.topk(log_probs, self.beam_size)\n\n                for log_prob, idx in zip(topk_log_probs, topk_indices):\n                    new_beams.append({\n                        \"score\": beam[\"score\"] + log_prob.item(),\n                        \"seq\": beam[\"seq\"] + [idx.item()],\n                        \"hidden\": new_hidden\n                    })\n\n            # Keep top `beam_size` beams\n            beams = sorted(new_beams, key=lambda x: x[\"score\"], reverse=True)[:self.beam_size]\n\n            # Early stopping if all beams end with <eos>\n            if all(beam[\"seq\"][-1] == eos_idx for beam in beams):\n                break\n\n        # Choose best beam\n        best_beam = max(beams, key=lambda x: x[\"score\"])\n        return best_beam[\"seq\"]\n\n\n\n\n\n# =======================\n# Train & Eval\n# =======================\ndef train(model, loader, criterion, optimizer, device):\n    model.train()\n    total_loss, total_correct, total_count = 0, 0, 0\n    for src, trg, src_lens, _ in loader:\n        src, trg = src.to(device), trg.to(device)\n        optimizer.zero_grad()\n        output, _ = model((src, src_lens), trg)\n        output_dim = output.shape[-1]\n        loss = criterion(output[:, 1:].reshape(-1, output_dim), trg[:, 1:].reshape(-1))\n        pred = output.argmax(2)\n        correct = ((pred[:, 1:] == trg[:, 1:]) & (trg[:, 1:] != 0)).sum().item()\n        total_correct += correct\n        total_count += (trg[:, 1:] != 0).sum().item()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    acc = 100.0 * total_correct / total_count\n    print(f\"Train Loss: {total_loss / len(loader):.4f}, Acc: {acc:.2f}%\")\n    return total_loss / len(loader), acc\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    total_loss, total_correct, total_count = 0, 0, 0\n    with torch.no_grad():\n        for src, trg, src_lens, _ in loader:\n            src, trg = src.to(device), trg.to(device)\n            output, _ = model((src, src_lens), trg, teacher_forcing_ratio=0)\n            output_dim = output.shape[-1]\n            loss = criterion(output[:, 1:].reshape(-1, output_dim), trg[:, 1:].reshape(-1))\n            pred = output.argmax(2)\n            correct = ((pred[:, 1:] == trg[:, 1:]) & (trg[:, 1:] != 0)).sum().item()\n            total_correct += correct\n            total_count += (trg[:, 1:] != 0).sum().item()\n            total_loss += loss.item()\n    acc = 100.0 * total_correct / total_count\n    print(f\"Val Loss: {total_loss / len(loader):.4f}, Acc: {acc:.2f}%\")\n    return total_loss / len(loader), acc\n\n# =======================\n# Main\n# =======================\ndef main():\n    wandb.init(config=default_config, project=\"dakshina-transliteration\")\n    config = wandb.config\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    inp_vocab, out_vocab = Vocab(), Vocab()\n    train_path = \"/kaggle/input/devnagiridata/hi.translit.sampled.train.tsv\"\n    dev_path = \"/kaggle/input/devnagiridata/hi.translit.sampled.dev.tsv\"\n    \n    train_data = TransliterationDataset(train_path, inp_vocab, out_vocab)\n    dev_data = TransliterationDataset(dev_path, inp_vocab, out_vocab)\n    \n    # Use config.batch_size for DataLoader\n    train_loader = DataLoader(train_data, batch_size=config.batch_size, \n                             shuffle=True, collate_fn=collate_fn)\n    dev_loader = DataLoader(dev_data, batch_size=config.batch_size,\n                           shuffle=False, collate_fn=collate_fn)\n\n    encoder = Encoder(inp_vocab.size, config.embedding_dim, config.hidden_dim,\n                     config.enc_layers, config.cell_type, config.dropout)\n    decoder = AttentionDecoder(out_vocab.size, config.embedding_dim, config.hidden_dim,\n                              config.dec_layers, config.cell_type, config.dropout,\n                              config.attention_type)\n    \n    model = Seq2Seq(encoder, decoder, config.enc_layers, config.dec_layers,\n                   config.cell_type, device, beam_size=config.beam_size).to(device)\n    \n    # Use config.learning_rate for optimizer\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    for epoch in range(config.epochs):\n        print(f\"Epoch {epoch+1}/{config.epochs}\")\n        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = evaluate(model, dev_loader, criterion, device)\n        wandb.log({\n            \"train_loss\": train_loss, \n            \"train_acc\": train_acc, \n            \"val_loss\": val_loss, \n            \"val_acc\": val_acc, \n            \"epoch\": epoch+1\n        })\n\n# =======================\nif __name__ == '__main__':\n    sweep_id = wandb.sweep(sweep_config, project=\"dakshina-transliteration-attention\")\n    wandb.agent(sweep_id, function=main, count=30)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T14:16:46.826237Z","iopub.execute_input":"2025-05-19T14:16:46.827014Z","iopub.status.idle":"2025-05-19T16:34:23.246442Z","shell.execute_reply.started":"2025-05-19T14:16:46.826985Z","shell.execute_reply":"2025-05-19T16:34:23.245752Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: 64q660zv\nSweep URL: https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kk1paf4n with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: general\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanglesh_dlass3\u001b[0m (\u001b[33mmanglesh_dl_ass3\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_141703-kk1paf4n</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/kk1paf4n' target=\"_blank\">gentle-sweep-1</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/kk1paf4n' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/kk1paf4n</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 2.5110, Acc: 29.00%\nVal Loss: 1.9818, Acc: 41.74%\nEpoch 2/10\nTrain Loss: 1.7008, Acc: 50.11%\nVal Loss: 1.3793, Acc: 56.66%\nEpoch 3/10\nTrain Loss: 1.3229, Acc: 61.12%\nVal Loss: 1.1319, Acc: 65.53%\nEpoch 4/10\nTrain Loss: 1.1588, Acc: 66.26%\nVal Loss: 1.0422, Acc: 68.36%\nEpoch 5/10\nTrain Loss: 1.0605, Acc: 69.47%\nVal Loss: 1.0014, Acc: 70.01%\nEpoch 6/10\nTrain Loss: 1.0092, Acc: 71.01%\nVal Loss: 0.9782, Acc: 70.04%\nEpoch 7/10\nTrain Loss: 0.9667, Acc: 72.27%\nVal Loss: 0.9751, Acc: 70.81%\nEpoch 8/10\nTrain Loss: 0.9433, Acc: 72.94%\nVal Loss: 0.9551, Acc: 71.02%\nEpoch 9/10\nTrain Loss: 0.9219, Acc: 73.60%\nVal Loss: 0.9505, Acc: 71.29%\nEpoch 10/10\nTrain Loss: 0.9076, Acc: 74.02%\nVal Loss: 0.9340, Acc: 71.47%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▄▆▇▇█████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▇▇██████</td></tr><tr><td>val_loss</td><td>█▄▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>74.02213</td></tr><tr><td>train_loss</td><td>0.90762</td></tr><tr><td>val_acc</td><td>71.46784</td></tr><tr><td>val_loss</td><td>0.93404</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gentle-sweep-1</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/kk1paf4n' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/kk1paf4n</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_141703-kk1paf4n/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z7kry7ze with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_141850-z7kry7ze</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/z7kry7ze' target=\"_blank\">vocal-sweep-2</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/z7kry7ze' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/z7kry7ze</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 2.8594, Acc: 20.93%\nVal Loss: 2.5821, Acc: 25.49%\nEpoch 2/10\nTrain Loss: 2.4010, Acc: 28.89%\nVal Loss: 2.2919, Acc: 29.30%\nEpoch 3/10\nTrain Loss: 2.0285, Acc: 38.11%\nVal Loss: 1.9301, Acc: 38.68%\nEpoch 4/10\nTrain Loss: 1.6875, Acc: 49.23%\nVal Loss: 1.6945, Acc: 47.08%\nEpoch 5/10\nTrain Loss: 1.4732, Acc: 56.66%\nVal Loss: 1.5609, Acc: 51.94%\nEpoch 6/10\nTrain Loss: 1.3461, Acc: 60.52%\nVal Loss: 1.4823, Acc: 54.67%\nEpoch 7/10\nTrain Loss: 1.2665, Acc: 62.74%\nVal Loss: 1.4252, Acc: 56.46%\nEpoch 8/10\nTrain Loss: 1.2155, Acc: 64.04%\nVal Loss: 1.3827, Acc: 57.94%\nEpoch 9/10\nTrain Loss: 1.1562, Acc: 65.99%\nVal Loss: 1.3538, Acc: 59.08%\nEpoch 10/10\nTrain Loss: 1.1214, Acc: 67.00%\nVal Loss: 1.3155, Acc: 60.74%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▂▄▅▆▇▇███</td></tr><tr><td>train_loss</td><td>█▆▅▃▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▄▅▆▇▇▇██</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>66.99628</td></tr><tr><td>train_loss</td><td>1.12138</td></tr><tr><td>val_acc</td><td>60.74188</td></tr><tr><td>val_loss</td><td>1.31552</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vocal-sweep-2</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/z7kry7ze' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/z7kry7ze</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_141850-z7kry7ze/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zd0d9rsu with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_142026-zd0d9rsu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/zd0d9rsu' target=\"_blank\">bumbling-sweep-3</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/zd0d9rsu' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/zd0d9rsu</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 2.5174, Acc: 25.81%\nVal Loss: 2.1532, Acc: 33.30%\nEpoch 2/15\nTrain Loss: 1.9083, Acc: 40.98%\nVal Loss: 1.7132, Acc: 45.88%\nEpoch 3/15\nTrain Loss: 1.5536, Acc: 51.78%\nVal Loss: 1.4826, Acc: 53.44%\nEpoch 4/15\nTrain Loss: 1.3771, Acc: 57.32%\nVal Loss: 1.3707, Acc: 57.18%\nEpoch 5/15\nTrain Loss: 1.2759, Acc: 60.66%\nVal Loss: 1.2924, Acc: 59.76%\nEpoch 6/15\nTrain Loss: 1.2133, Acc: 62.79%\nVal Loss: 1.2253, Acc: 61.99%\nEpoch 7/15\nTrain Loss: 1.1586, Acc: 64.62%\nVal Loss: 1.1762, Acc: 64.34%\nEpoch 8/15\nTrain Loss: 1.1129, Acc: 66.35%\nVal Loss: 1.1528, Acc: 64.93%\nEpoch 9/15\nTrain Loss: 1.0816, Acc: 67.48%\nVal Loss: 1.1283, Acc: 66.03%\nEpoch 10/15\nTrain Loss: 1.0536, Acc: 68.38%\nVal Loss: 1.1321, Acc: 66.47%\nEpoch 11/15\nTrain Loss: 1.0402, Acc: 68.86%\nVal Loss: 1.1032, Acc: 66.82%\nEpoch 12/15\nTrain Loss: 1.0175, Acc: 69.68%\nVal Loss: 1.0828, Acc: 67.74%\nEpoch 13/15\nTrain Loss: 0.9974, Acc: 70.33%\nVal Loss: 1.0473, Acc: 67.78%\nEpoch 14/15\nTrain Loss: 0.9874, Acc: 70.58%\nVal Loss: 1.0524, Acc: 68.34%\nEpoch 15/15\nTrain Loss: 0.9642, Acc: 71.38%\nVal Loss: 1.0491, Acc: 68.62%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▇▇▇▇██████</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>71.37816</td></tr><tr><td>train_loss</td><td>0.9642</td></tr><tr><td>val_acc</td><td>68.62359</td></tr><tr><td>val_loss</td><td>1.04909</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">bumbling-sweep-3</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/zd0d9rsu' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/zd0d9rsu</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_142026-zd0d9rsu/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yhqr0gl6 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: general\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_142257-yhqr0gl6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/yhqr0gl6' target=\"_blank\">peach-sweep-4</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/yhqr0gl6' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/yhqr0gl6</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 1.4411, Acc: 58.91%\nVal Loss: 1.0458, Acc: 69.22%\nEpoch 2/15\nTrain Loss: 0.8480, Acc: 75.06%\nVal Loss: 0.9443, Acc: 71.39%\nEpoch 3/15\nTrain Loss: 0.7820, Acc: 76.61%\nVal Loss: 0.9259, Acc: 71.28%\nEpoch 4/15\nTrain Loss: 0.7430, Acc: 77.54%\nVal Loss: 0.9123, Acc: 72.36%\nEpoch 5/15\nTrain Loss: 0.6997, Acc: 78.80%\nVal Loss: 0.8711, Acc: 73.25%\nEpoch 6/15\nTrain Loss: 0.7317, Acc: 77.84%\nVal Loss: 0.8825, Acc: 73.04%\nEpoch 7/15\nTrain Loss: 0.6677, Acc: 79.61%\nVal Loss: 0.8589, Acc: 73.20%\nEpoch 8/15\nTrain Loss: 0.6786, Acc: 79.02%\nVal Loss: 0.8512, Acc: 73.68%\nEpoch 9/15\nTrain Loss: 0.7135, Acc: 78.02%\nVal Loss: 0.8835, Acc: 72.50%\nEpoch 10/15\nTrain Loss: 0.6985, Acc: 78.56%\nVal Loss: 0.8656, Acc: 73.36%\nEpoch 11/15\nTrain Loss: 0.6477, Acc: 80.06%\nVal Loss: 0.8398, Acc: 74.10%\nEpoch 12/15\nTrain Loss: 0.6419, Acc: 80.11%\nVal Loss: 0.8249, Acc: 74.11%\nEpoch 13/15\nTrain Loss: 0.6534, Acc: 79.87%\nVal Loss: 0.8633, Acc: 73.83%\nEpoch 14/15\nTrain Loss: 0.6161, Acc: 81.04%\nVal Loss: 0.8324, Acc: 73.55%\nEpoch 15/15\nTrain Loss: 0.6433, Acc: 80.09%\nVal Loss: 0.8361, Acc: 73.68%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇█▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▄▅▇▆▇▇▆▇███▇▇</td></tr><tr><td>val_loss</td><td>█▅▄▄▂▃▂▂▃▂▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>80.08619</td></tr><tr><td>train_loss</td><td>0.64332</td></tr><tr><td>val_acc</td><td>73.67553</td></tr><tr><td>val_loss</td><td>0.83605</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">peach-sweep-4</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/yhqr0gl6' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/yhqr0gl6</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_142257-yhqr0gl6/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w75cha9e with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_142639-w75cha9e</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/w75cha9e' target=\"_blank\">cosmic-sweep-5</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/w75cha9e' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/w75cha9e</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 1.4732, Acc: 55.43%\nVal Loss: 1.0160, Acc: 69.63%\nEpoch 2/15\nTrain Loss: 0.8437, Acc: 74.68%\nVal Loss: 0.9017, Acc: 71.98%\nEpoch 3/15\nTrain Loss: 0.7513, Acc: 77.02%\nVal Loss: 0.8873, Acc: 72.51%\nEpoch 4/15\nTrain Loss: 0.6997, Acc: 78.38%\nVal Loss: 0.8793, Acc: 73.36%\nEpoch 5/15\nTrain Loss: 0.6681, Acc: 79.17%\nVal Loss: 0.8600, Acc: 73.56%\nEpoch 6/15\nTrain Loss: 0.6406, Acc: 79.86%\nVal Loss: 0.8276, Acc: 74.35%\nEpoch 7/15\nTrain Loss: 0.6221, Acc: 80.42%\nVal Loss: 0.8281, Acc: 74.25%\nEpoch 8/15\nTrain Loss: 0.6135, Acc: 80.58%\nVal Loss: 0.8139, Acc: 74.38%\nEpoch 9/15\nTrain Loss: 0.5996, Acc: 81.07%\nVal Loss: 0.7871, Acc: 74.82%\nEpoch 10/15\nTrain Loss: 0.5896, Acc: 81.21%\nVal Loss: 0.8049, Acc: 75.28%\nEpoch 11/15\nTrain Loss: 0.5782, Acc: 81.61%\nVal Loss: 0.8288, Acc: 75.32%\nEpoch 12/15\nTrain Loss: 0.5746, Acc: 81.61%\nVal Loss: 0.8136, Acc: 75.42%\nEpoch 13/15\nTrain Loss: 0.5725, Acc: 81.62%\nVal Loss: 0.8254, Acc: 75.34%\nEpoch 14/15\nTrain Loss: 0.5710, Acc: 81.58%\nVal Loss: 0.7887, Acc: 75.52%\nEpoch 15/15\nTrain Loss: 0.5529, Acc: 82.35%\nVal Loss: 0.7825, Acc: 75.71%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▄▅▆▆▆▆▇██████</td></tr><tr><td>val_loss</td><td>█▅▄▄▃▂▂▂▁▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>82.3508</td></tr><tr><td>train_loss</td><td>0.55287</td></tr><tr><td>val_acc</td><td>75.70672</td></tr><tr><td>val_loss</td><td>0.78246</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">cosmic-sweep-5</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/w75cha9e' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/w75cha9e</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_142639-w75cha9e/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n67ny8ll with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: general\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_143157-n67ny8ll</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/n67ny8ll' target=\"_blank\">vital-sweep-6</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/n67ny8ll' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/n67ny8ll</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 1.5483, Acc: 54.28%\nVal Loss: 1.3092, Acc: 59.25%\nEpoch 2/15\nTrain Loss: 1.3283, Acc: 60.53%\nVal Loss: 1.3366, Acc: 58.21%\nEpoch 3/15\nTrain Loss: 1.2633, Acc: 62.46%\nVal Loss: 1.1851, Acc: 62.79%\nEpoch 4/15\nTrain Loss: 1.0925, Acc: 67.59%\nVal Loss: 1.1708, Acc: 63.94%\nEpoch 5/15\nTrain Loss: 1.2435, Acc: 63.32%\nVal Loss: 1.1732, Acc: 63.95%\nEpoch 6/15\nTrain Loss: 1.2622, Acc: 62.71%\nVal Loss: 1.2109, Acc: 63.22%\nEpoch 7/15\nTrain Loss: 1.1317, Acc: 66.46%\nVal Loss: 1.1001, Acc: 66.65%\nEpoch 8/15\nTrain Loss: 1.0772, Acc: 68.46%\nVal Loss: 1.2319, Acc: 62.06%\nEpoch 9/15\nTrain Loss: 1.1424, Acc: 66.46%\nVal Loss: 1.1441, Acc: 64.76%\nEpoch 10/15\nTrain Loss: 1.1595, Acc: 66.05%\nVal Loss: 1.3471, Acc: 60.34%\nEpoch 11/15\nTrain Loss: 1.2318, Acc: 64.25%\nVal Loss: 1.1066, Acc: 66.90%\nEpoch 12/15\nTrain Loss: 1.0795, Acc: 68.77%\nVal Loss: 1.0838, Acc: 67.83%\nEpoch 13/15\nTrain Loss: 1.1133, Acc: 67.77%\nVal Loss: 1.1428, Acc: 65.92%\nEpoch 14/15\nTrain Loss: 1.1924, Acc: 65.39%\nVal Loss: 1.2334, Acc: 63.05%\nEpoch 15/15\nTrain Loss: 1.1052, Acc: 68.02%\nVal Loss: 1.0701, Acc: 67.62%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▄▅▇▅▅▇█▇▇▆██▆█</td></tr><tr><td>train_loss</td><td>█▅▄▁▃▄▂▁▂▂▃▁▂▃▁</td></tr><tr><td>val_acc</td><td>▂▁▄▅▅▅▇▄▆▃▇█▇▅█</td></tr><tr><td>val_loss</td><td>▇█▄▄▄▅▂▅▃█▂▁▃▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>68.01712</td></tr><tr><td>train_loss</td><td>1.10516</td></tr><tr><td>val_acc</td><td>67.62246</td></tr><tr><td>val_loss</td><td>1.07009</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vital-sweep-6</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/n67ny8ll' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/n67ny8ll</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_143157-n67ny8ll/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nu7qlc0k with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_143919-nu7qlc0k</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/nu7qlc0k' target=\"_blank\">hopeful-sweep-7</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/nu7qlc0k' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/nu7qlc0k</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.8805, Acc: 44.40%\nVal Loss: 1.1568, Acc: 66.07%\nEpoch 2/10\nTrain Loss: 0.8845, Acc: 73.82%\nVal Loss: 0.9274, Acc: 71.81%\nEpoch 3/10\nTrain Loss: 0.7638, Acc: 77.16%\nVal Loss: 0.8985, Acc: 72.59%\nEpoch 4/10\nTrain Loss: 0.7122, Acc: 78.52%\nVal Loss: 0.8970, Acc: 73.11%\nEpoch 5/10\nTrain Loss: 0.6927, Acc: 78.81%\nVal Loss: 0.8723, Acc: 73.46%\nEpoch 6/10\nTrain Loss: 0.6513, Acc: 80.06%\nVal Loss: 0.8552, Acc: 73.83%\nEpoch 7/10\nTrain Loss: 0.6379, Acc: 80.32%\nVal Loss: 0.8488, Acc: 73.69%\nEpoch 8/10\nTrain Loss: 0.6217, Acc: 80.69%\nVal Loss: 0.8550, Acc: 73.93%\nEpoch 9/10\nTrain Loss: 0.6201, Acc: 80.60%\nVal Loss: 0.8358, Acc: 74.37%\nEpoch 10/10\nTrain Loss: 0.6000, Acc: 81.23%\nVal Loss: 0.8255, Acc: 74.43%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▃▃▃▂▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>81.23367</td></tr><tr><td>train_loss</td><td>0.60001</td></tr><tr><td>val_acc</td><td>74.43072</td></tr><tr><td>val_loss</td><td>0.8255</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">hopeful-sweep-7</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/nu7qlc0k' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/nu7qlc0k</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_143919-nu7qlc0k/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vrw1qiba with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_144236-vrw1qiba</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vrw1qiba' target=\"_blank\">fearless-sweep-8</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vrw1qiba' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vrw1qiba</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.8408, Acc: 42.82%\nVal Loss: 1.1136, Acc: 64.21%\nEpoch 2/10\nTrain Loss: 0.9016, Acc: 71.88%\nVal Loss: 0.8618, Acc: 72.08%\nEpoch 3/10\nTrain Loss: 0.7479, Acc: 76.40%\nVal Loss: 0.8066, Acc: 73.81%\nEpoch 4/10\nTrain Loss: 0.6717, Acc: 78.76%\nVal Loss: 0.8281, Acc: 74.23%\nEpoch 5/10\nTrain Loss: 0.6313, Acc: 80.08%\nVal Loss: 0.7937, Acc: 74.88%\nEpoch 6/10\nTrain Loss: 0.6036, Acc: 80.82%\nVal Loss: 0.8305, Acc: 75.22%\nEpoch 7/10\nTrain Loss: 0.5857, Acc: 81.32%\nVal Loss: 0.7871, Acc: 75.57%\nEpoch 8/10\nTrain Loss: 0.5755, Acc: 81.58%\nVal Loss: 0.7826, Acc: 75.82%\nEpoch 9/10\nTrain Loss: 0.5514, Acc: 82.36%\nVal Loss: 0.7783, Acc: 75.75%\nEpoch 10/10\nTrain Loss: 0.5404, Acc: 82.65%\nVal Loss: 0.7910, Acc: 75.84%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇██████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>82.64877</td></tr><tr><td>train_loss</td><td>0.54038</td></tr><tr><td>val_acc</td><td>75.84271</td></tr><tr><td>val_loss</td><td>0.79096</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fearless-sweep-8</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vrw1qiba' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vrw1qiba</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_144236-vrw1qiba/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wm1p0ya7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_144634-wm1p0ya7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/wm1p0ya7' target=\"_blank\">driven-sweep-9</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/wm1p0ya7' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/wm1p0ya7</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 2.5955, Acc: 26.04%\nVal Loss: 2.1989, Acc: 34.41%\nEpoch 2/15\nTrain Loss: 1.9017, Acc: 43.22%\nVal Loss: 1.5169, Acc: 53.87%\nEpoch 3/15\nTrain Loss: 1.3732, Acc: 59.15%\nVal Loss: 1.1632, Acc: 65.06%\nEpoch 4/15\nTrain Loss: 1.1540, Acc: 66.07%\nVal Loss: 1.0790, Acc: 67.20%\nEpoch 5/15\nTrain Loss: 1.0612, Acc: 68.94%\nVal Loss: 1.0271, Acc: 68.30%\nEpoch 6/15\nTrain Loss: 1.0144, Acc: 70.23%\nVal Loss: 1.0004, Acc: 69.46%\nEpoch 7/15\nTrain Loss: 0.9723, Acc: 71.48%\nVal Loss: 1.0115, Acc: 68.95%\nEpoch 8/15\nTrain Loss: 0.9468, Acc: 72.12%\nVal Loss: 0.9160, Acc: 71.81%\nEpoch 9/15\nTrain Loss: 0.9189, Acc: 72.93%\nVal Loss: 0.9196, Acc: 71.93%\nEpoch 10/15\nTrain Loss: 0.9006, Acc: 73.51%\nVal Loss: 0.9313, Acc: 71.81%\nEpoch 11/15\nTrain Loss: 0.8851, Acc: 73.91%\nVal Loss: 0.9158, Acc: 72.55%\nEpoch 12/15\nTrain Loss: 0.8813, Acc: 73.96%\nVal Loss: 0.9167, Acc: 72.11%\nEpoch 13/15\nTrain Loss: 0.8626, Acc: 74.51%\nVal Loss: 0.9207, Acc: 72.39%\nEpoch 14/15\nTrain Loss: 0.8585, Acc: 74.54%\nVal Loss: 0.9101, Acc: 72.66%\nEpoch 15/15\nTrain Loss: 0.8387, Acc: 75.26%\nVal Loss: 0.9085, Acc: 72.49%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▃▆▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▇▇▇▇▇████████</td></tr><tr><td>val_loss</td><td>█▄▂▂▂▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>75.25569</td></tr><tr><td>train_loss</td><td>0.83872</td></tr><tr><td>val_acc</td><td>72.49212</td></tr><tr><td>val_loss</td><td>0.90851</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">driven-sweep-9</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/wm1p0ya7' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/wm1p0ya7</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_144634-wm1p0ya7/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3ecgr25p with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_144930-3ecgr25p</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/3ecgr25p' target=\"_blank\">iconic-sweep-10</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/3ecgr25p' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/3ecgr25p</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 2.5609, Acc: 26.99%\nVal Loss: 2.1108, Acc: 33.60%\nEpoch 2/10\nTrain Loss: 2.0077, Acc: 35.21%\nVal Loss: 1.7490, Acc: 41.19%\nEpoch 3/10\nTrain Loss: 1.7446, Acc: 41.12%\nVal Loss: 1.5677, Acc: 45.49%\nEpoch 4/10\nTrain Loss: 1.5799, Acc: 46.27%\nVal Loss: 1.4801, Acc: 48.69%\nEpoch 5/10\nTrain Loss: 1.4246, Acc: 52.02%\nVal Loss: 1.2667, Acc: 56.98%\nEpoch 6/10\nTrain Loss: 1.1684, Acc: 62.44%\nVal Loss: 1.0664, Acc: 65.71%\nEpoch 7/10\nTrain Loss: 1.0131, Acc: 68.74%\nVal Loss: 0.9662, Acc: 69.63%\nEpoch 8/10\nTrain Loss: 0.9299, Acc: 71.46%\nVal Loss: 0.9219, Acc: 71.12%\nEpoch 9/10\nTrain Loss: 0.8688, Acc: 73.43%\nVal Loss: 0.9018, Acc: 71.51%\nEpoch 10/10\nTrain Loss: 0.8289, Acc: 74.61%\nVal Loss: 0.8714, Acc: 72.46%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▂▃▄▅▆▇███</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▄▅▇▇███</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>74.60539</td></tr><tr><td>train_loss</td><td>0.8289</td></tr><tr><td>val_acc</td><td>72.46029</td></tr><tr><td>val_loss</td><td>0.87139</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">iconic-sweep-10</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/3ecgr25p' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/3ecgr25p</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_144930-3ecgr25p/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e1hiotdo with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_145327-e1hiotdo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/e1hiotdo' target=\"_blank\">amber-sweep-11</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/e1hiotdo' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/e1hiotdo</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.9734, Acc: 39.25%\nVal Loss: 1.1697, Acc: 63.23%\nEpoch 2/10\nTrain Loss: 1.0246, Acc: 68.52%\nVal Loss: 0.9209, Acc: 71.17%\nEpoch 3/10\nTrain Loss: 0.8391, Acc: 74.36%\nVal Loss: 0.8998, Acc: 71.52%\nEpoch 4/10\nTrain Loss: 0.7618, Acc: 76.42%\nVal Loss: 0.8389, Acc: 73.46%\nEpoch 5/10\nTrain Loss: 0.7143, Acc: 77.67%\nVal Loss: 0.8374, Acc: 74.01%\nEpoch 6/10\nTrain Loss: 0.6773, Acc: 78.86%\nVal Loss: 0.8301, Acc: 74.18%\nEpoch 7/10\nTrain Loss: 0.6496, Acc: 79.65%\nVal Loss: 0.8580, Acc: 74.17%\nEpoch 8/10\nTrain Loss: 0.6303, Acc: 80.14%\nVal Loss: 0.8562, Acc: 74.25%\nEpoch 9/10\nTrain Loss: 0.6158, Acc: 80.57%\nVal Loss: 0.8267, Acc: 74.64%\nEpoch 10/10\nTrain Loss: 0.6044, Acc: 80.92%\nVal Loss: 0.7977, Acc: 75.33%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▃▃▂▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>80.91776</td></tr><tr><td>train_loss</td><td>0.60442</td></tr><tr><td>val_acc</td><td>75.33347</td></tr><tr><td>val_loss</td><td>0.7977</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">amber-sweep-11</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/e1hiotdo' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/e1hiotdo</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_145327-e1hiotdo/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gj8qzdck with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_145719-gj8qzdck</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/gj8qzdck' target=\"_blank\">swift-sweep-12</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/gj8qzdck' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/gj8qzdck</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 2.2572, Acc: 32.28%\nVal Loss: 1.7513, Acc: 41.84%\nEpoch 2/15\nTrain Loss: 1.4334, Acc: 55.80%\nVal Loss: 1.0554, Acc: 68.41%\nEpoch 3/15\nTrain Loss: 1.0429, Acc: 69.04%\nVal Loss: 0.9534, Acc: 71.40%\nEpoch 4/15\nTrain Loss: 0.9300, Acc: 72.32%\nVal Loss: 0.9132, Acc: 72.43%\nEpoch 5/15\nTrain Loss: 0.8649, Acc: 74.08%\nVal Loss: 0.9180, Acc: 72.31%\nEpoch 6/15\nTrain Loss: 0.8280, Acc: 74.99%\nVal Loss: 0.8964, Acc: 73.03%\nEpoch 7/15\nTrain Loss: 0.7859, Acc: 76.34%\nVal Loss: 0.8752, Acc: 73.79%\nEpoch 8/15\nTrain Loss: 0.7617, Acc: 77.00%\nVal Loss: 0.8549, Acc: 74.27%\nEpoch 9/15\nTrain Loss: 0.7369, Acc: 77.72%\nVal Loss: 0.8398, Acc: 74.51%\nEpoch 10/15\nTrain Loss: 0.7195, Acc: 78.18%\nVal Loss: 0.8544, Acc: 74.62%\nEpoch 11/15\nTrain Loss: 0.7056, Acc: 78.58%\nVal Loss: 0.8485, Acc: 74.58%\nEpoch 12/15\nTrain Loss: 0.6942, Acc: 78.81%\nVal Loss: 0.8479, Acc: 74.88%\nEpoch 13/15\nTrain Loss: 0.6825, Acc: 79.14%\nVal Loss: 0.8410, Acc: 75.09%\nEpoch 14/15\nTrain Loss: 0.6793, Acc: 79.06%\nVal Loss: 0.8267, Acc: 75.10%\nEpoch 15/15\nTrain Loss: 0.6655, Acc: 79.47%\nVal Loss: 0.8229, Acc: 75.24%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▄▆▇▇▇█████████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇██████████</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>79.46679</td></tr><tr><td>train_loss</td><td>0.66553</td></tr><tr><td>val_acc</td><td>75.23799</td></tr><tr><td>val_loss</td><td>0.82287</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">swift-sweep-12</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/gj8qzdck' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/gj8qzdck</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_145719-gj8qzdck/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oskj9yx6 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_150703-oskj9yx6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/oskj9yx6' target=\"_blank\">lunar-sweep-13</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/oskj9yx6' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/oskj9yx6</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.4046, Acc: 56.68%\nVal Loss: 0.9350, Acc: 70.49%\nEpoch 2/10\nTrain Loss: 0.7508, Acc: 76.79%\nVal Loss: 0.8580, Acc: 73.27%\nEpoch 3/10\nTrain Loss: 0.6615, Acc: 79.14%\nVal Loss: 0.8463, Acc: 74.17%\nEpoch 4/10\nTrain Loss: 0.6086, Acc: 80.74%\nVal Loss: 0.8234, Acc: 75.17%\nEpoch 5/10\nTrain Loss: 0.5759, Acc: 81.67%\nVal Loss: 0.7827, Acc: 74.90%\nEpoch 6/10\nTrain Loss: 0.5585, Acc: 82.06%\nVal Loss: 0.8171, Acc: 75.12%\nEpoch 7/10\nTrain Loss: 0.5357, Acc: 82.79%\nVal Loss: 0.7760, Acc: 76.07%\nEpoch 8/10\nTrain Loss: 0.5161, Acc: 83.33%\nVal Loss: 0.8172, Acc: 75.91%\nEpoch 9/10\nTrain Loss: 0.5048, Acc: 83.57%\nVal Loss: 0.7907, Acc: 75.76%\nEpoch 10/10\nTrain Loss: 0.4957, Acc: 83.74%\nVal Loss: 0.8165, Acc: 75.94%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▄▃▁▃▁▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>83.73969</td></tr><tr><td>train_loss</td><td>0.49566</td></tr><tr><td>val_acc</td><td>75.94398</td></tr><tr><td>val_loss</td><td>0.81648</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lunar-sweep-13</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/oskj9yx6' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/oskj9yx6</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_150703-oskj9yx6/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oop6438f with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_151351-oop6438f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/oop6438f' target=\"_blank\">confused-sweep-14</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/oop6438f' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/oop6438f</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 1.5673, Acc: 51.57%\nVal Loss: 0.9523, Acc: 70.36%\nEpoch 2/15\nTrain Loss: 0.8201, Acc: 74.98%\nVal Loss: 0.8907, Acc: 73.09%\nEpoch 3/15\nTrain Loss: 0.7193, Acc: 77.99%\nVal Loss: 0.8706, Acc: 73.72%\nEpoch 4/15\nTrain Loss: 0.6774, Acc: 79.13%\nVal Loss: 0.8422, Acc: 74.10%\nEpoch 5/15\nTrain Loss: 0.6409, Acc: 80.29%\nVal Loss: 0.8882, Acc: 73.98%\nEpoch 6/15\nTrain Loss: 0.6311, Acc: 80.24%\nVal Loss: 0.8514, Acc: 74.81%\nEpoch 7/15\nTrain Loss: 0.6095, Acc: 80.94%\nVal Loss: 0.8620, Acc: 74.52%\nEpoch 8/15\nTrain Loss: 0.5893, Acc: 81.41%\nVal Loss: 0.8133, Acc: 75.04%\nEpoch 9/15\nTrain Loss: 0.5806, Acc: 81.66%\nVal Loss: 0.8053, Acc: 75.37%\nEpoch 10/15\nTrain Loss: 0.5764, Acc: 81.65%\nVal Loss: 0.8388, Acc: 75.37%\nEpoch 11/15\nTrain Loss: 0.5600, Acc: 82.25%\nVal Loss: 0.7970, Acc: 76.08%\nEpoch 12/15\nTrain Loss: 0.5469, Acc: 82.58%\nVal Loss: 0.8427, Acc: 75.69%\nEpoch 13/15\nTrain Loss: 0.5532, Acc: 82.23%\nVal Loss: 0.8203, Acc: 76.15%\nEpoch 14/15\nTrain Loss: 0.5329, Acc: 82.88%\nVal Loss: 0.8377, Acc: 76.05%\nEpoch 15/15\nTrain Loss: 0.5302, Acc: 83.01%\nVal Loss: 0.8105, Acc: 76.03%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇█████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▅▆▆▇▇▇█▇███</td></tr><tr><td>val_loss</td><td>█▅▄▃▅▃▄▂▁▃▁▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>83.008</td></tr><tr><td>train_loss</td><td>0.53022</td></tr><tr><td>val_acc</td><td>76.03368</td></tr><tr><td>val_loss</td><td>0.8105</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">confused-sweep-14</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/oop6438f' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/oop6438f</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_151351-oop6438f/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vf7xpo41 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_151707-vf7xpo41</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vf7xpo41' target=\"_blank\">azure-sweep-15</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vf7xpo41' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vf7xpo41</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 1.7330, Acc: 46.50%\nVal Loss: 0.9966, Acc: 68.05%\nEpoch 2/15\nTrain Loss: 0.9578, Acc: 70.21%\nVal Loss: 0.9333, Acc: 71.18%\nEpoch 3/15\nTrain Loss: 0.8146, Acc: 74.97%\nVal Loss: 0.8729, Acc: 73.35%\nEpoch 4/15\nTrain Loss: 0.7570, Acc: 76.58%\nVal Loss: 0.8416, Acc: 73.85%\nEpoch 5/15\nTrain Loss: 0.7062, Acc: 78.17%\nVal Loss: 0.8570, Acc: 74.88%\nEpoch 6/15\nTrain Loss: 0.6742, Acc: 79.21%\nVal Loss: 0.8799, Acc: 74.75%\nEpoch 7/15\nTrain Loss: 0.6451, Acc: 80.02%\nVal Loss: 0.8132, Acc: 74.91%\nEpoch 8/15\nTrain Loss: 0.6207, Acc: 80.71%\nVal Loss: 0.8467, Acc: 75.56%\nEpoch 9/15\nTrain Loss: 0.6167, Acc: 80.77%\nVal Loss: 0.8610, Acc: 75.24%\nEpoch 10/15\nTrain Loss: 0.6051, Acc: 80.92%\nVal Loss: 0.8614, Acc: 75.21%\nEpoch 11/15\nTrain Loss: 0.5856, Acc: 81.57%\nVal Loss: 0.8465, Acc: 75.60%\nEpoch 12/15\nTrain Loss: 0.5792, Acc: 81.66%\nVal Loss: 0.8150, Acc: 75.65%\nEpoch 13/15\nTrain Loss: 0.5691, Acc: 82.00%\nVal Loss: 0.8408, Acc: 75.73%\nEpoch 14/15\nTrain Loss: 0.5706, Acc: 81.84%\nVal Loss: 0.8100, Acc: 75.62%\nEpoch 15/15\nTrain Loss: 0.5531, Acc: 82.46%\nVal Loss: 0.8200, Acc: 76.13%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇█████████</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇▇▇█▇▇█████</td></tr><tr><td>val_loss</td><td>█▆▃▂▃▄▁▂▃▃▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>82.46392</td></tr><tr><td>train_loss</td><td>0.55308</td></tr><tr><td>val_acc</td><td>76.13206</td></tr><tr><td>val_loss</td><td>0.82</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">azure-sweep-15</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vf7xpo41' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vf7xpo41</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_151707-vf7xpo41/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 682bk2iw with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_152029-682bk2iw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/682bk2iw' target=\"_blank\">snowy-sweep-16</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/682bk2iw' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/682bk2iw</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 2.1580, Acc: 37.31%\nVal Loss: 1.2994, Acc: 60.84%\nEpoch 2/10\nTrain Loss: 1.3232, Acc: 61.32%\nVal Loss: 1.0723, Acc: 68.42%\nEpoch 3/10\nTrain Loss: 1.1875, Acc: 65.59%\nVal Loss: 1.0218, Acc: 69.09%\nEpoch 4/10\nTrain Loss: 1.1235, Acc: 67.59%\nVal Loss: 1.0007, Acc: 70.46%\nEpoch 5/10\nTrain Loss: 1.0876, Acc: 68.58%\nVal Loss: 0.9795, Acc: 71.07%\nEpoch 6/10\nTrain Loss: 1.0632, Acc: 69.42%\nVal Loss: 0.9620, Acc: 71.02%\nEpoch 7/10\nTrain Loss: 1.0424, Acc: 69.96%\nVal Loss: 0.9723, Acc: 70.74%\nEpoch 8/10\nTrain Loss: 1.0245, Acc: 70.54%\nVal Loss: 0.9795, Acc: 71.00%\nEpoch 9/10\nTrain Loss: 1.0126, Acc: 70.90%\nVal Loss: 0.9656, Acc: 71.60%\nEpoch 10/10\nTrain Loss: 1.0012, Acc: 71.22%\nVal Loss: 0.9512, Acc: 71.67%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▆▇██▇███</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>71.21538</td></tr><tr><td>train_loss</td><td>1.00123</td></tr><tr><td>val_acc</td><td>71.66749</td></tr><tr><td>val_loss</td><td>0.95121</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">snowy-sweep-16</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/682bk2iw' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/682bk2iw</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_152029-682bk2iw/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y0vvjpjv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_152603-y0vvjpjv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/y0vvjpjv' target=\"_blank\">vibrant-sweep-17</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/y0vvjpjv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/y0vvjpjv</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 2.1848, Acc: 36.30%\nVal Loss: 1.4162, Acc: 56.57%\nEpoch 2/10\nTrain Loss: 1.1347, Acc: 65.97%\nVal Loss: 0.9780, Acc: 69.51%\nEpoch 3/10\nTrain Loss: 0.9094, Acc: 72.94%\nVal Loss: 0.9145, Acc: 71.97%\nEpoch 4/10\nTrain Loss: 0.8226, Acc: 75.40%\nVal Loss: 0.8949, Acc: 72.81%\nEpoch 5/10\nTrain Loss: 0.7705, Acc: 76.84%\nVal Loss: 0.8672, Acc: 73.48%\nEpoch 6/10\nTrain Loss: 0.7365, Acc: 77.69%\nVal Loss: 0.8350, Acc: 73.43%\nEpoch 7/10\nTrain Loss: 0.7109, Acc: 78.32%\nVal Loss: 0.8462, Acc: 74.03%\nEpoch 8/10\nTrain Loss: 0.6881, Acc: 78.93%\nVal Loss: 0.8172, Acc: 74.46%\nEpoch 9/10\nTrain Loss: 0.6676, Acc: 79.38%\nVal Loss: 0.8003, Acc: 74.72%\nEpoch 10/10\nTrain Loss: 0.6536, Acc: 79.73%\nVal Loss: 0.7954, Acc: 74.49%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇██████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▇▇██████</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>79.72945</td></tr><tr><td>train_loss</td><td>0.65364</td></tr><tr><td>val_acc</td><td>74.49437</td></tr><tr><td>val_loss</td><td>0.79536</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vibrant-sweep-17</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/y0vvjpjv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/y0vvjpjv</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_152603-y0vvjpjv/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1sxvkv5x with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_152823-1sxvkv5x</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/1sxvkv5x' target=\"_blank\">pious-sweep-18</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/1sxvkv5x' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/1sxvkv5x</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.8565, Acc: 44.54%\nVal Loss: 1.0665, Acc: 67.06%\nEpoch 2/10\nTrain Loss: 0.9642, Acc: 70.94%\nVal Loss: 0.9299, Acc: 71.33%\nEpoch 3/10\nTrain Loss: 0.8129, Acc: 75.43%\nVal Loss: 0.9166, Acc: 72.70%\nEpoch 4/10\nTrain Loss: 0.7393, Acc: 77.52%\nVal Loss: 0.8785, Acc: 73.05%\nEpoch 5/10\nTrain Loss: 0.7016, Acc: 78.41%\nVal Loss: 0.8376, Acc: 73.92%\nEpoch 6/10\nTrain Loss: 0.6830, Acc: 78.70%\nVal Loss: 0.8279, Acc: 74.46%\nEpoch 7/10\nTrain Loss: 0.6344, Acc: 80.40%\nVal Loss: 0.8265, Acc: 75.28%\nEpoch 8/10\nTrain Loss: 0.6350, Acc: 80.02%\nVal Loss: 0.8087, Acc: 75.31%\nEpoch 9/10\nTrain Loss: 0.6265, Acc: 80.15%\nVal Loss: 0.8231, Acc: 74.95%\nEpoch 10/10\nTrain Loss: 0.5942, Acc: 81.39%\nVal Loss: 0.8046, Acc: 75.63%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇▇██▇█</td></tr><tr><td>val_loss</td><td>█▄▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>81.39287</td></tr><tr><td>train_loss</td><td>0.5942</td></tr><tr><td>val_acc</td><td>75.63439</td></tr><tr><td>val_loss</td><td>0.80463</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">pious-sweep-18</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/1sxvkv5x' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/1sxvkv5x</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_152823-1sxvkv5x/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eqpz333v with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_153039-eqpz333v</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/eqpz333v' target=\"_blank\">rural-sweep-19</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/eqpz333v' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/eqpz333v</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 2.4409, Acc: 28.78%\nVal Loss: 2.0366, Acc: 35.57%\nEpoch 2/15\nTrain Loss: 1.7160, Acc: 47.78%\nVal Loss: 1.4151, Acc: 58.57%\nEpoch 3/15\nTrain Loss: 1.1653, Acc: 67.04%\nVal Loss: 1.1424, Acc: 67.59%\nEpoch 4/15\nTrain Loss: 0.9786, Acc: 72.42%\nVal Loss: 1.0481, Acc: 69.87%\nEpoch 5/15\nTrain Loss: 0.8922, Acc: 74.40%\nVal Loss: 0.9820, Acc: 71.76%\nEpoch 6/15\nTrain Loss: 0.8450, Acc: 75.52%\nVal Loss: 0.9760, Acc: 71.70%\nEpoch 7/15\nTrain Loss: 0.8054, Acc: 76.48%\nVal Loss: 1.0276, Acc: 70.94%\nEpoch 8/15\nTrain Loss: 0.7711, Acc: 77.39%\nVal Loss: 0.9448, Acc: 72.84%\nEpoch 9/15\nTrain Loss: 0.7504, Acc: 77.85%\nVal Loss: 0.9140, Acc: 73.20%\nEpoch 10/15\nTrain Loss: 0.7296, Acc: 78.43%\nVal Loss: 0.9243, Acc: 73.13%\nEpoch 11/15\nTrain Loss: 0.7190, Acc: 78.51%\nVal Loss: 0.9042, Acc: 73.53%\nEpoch 12/15\nTrain Loss: 0.7047, Acc: 78.81%\nVal Loss: 0.9551, Acc: 72.63%\nEpoch 13/15\nTrain Loss: 0.6898, Acc: 79.20%\nVal Loss: 0.9016, Acc: 73.65%\nEpoch 14/15\nTrain Loss: 0.6815, Acc: 79.40%\nVal Loss: 0.8858, Acc: 73.68%\nEpoch 15/15\nTrain Loss: 0.6680, Acc: 79.73%\nVal Loss: 0.9003, Acc: 73.87%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▄▆▇▇▇█████████</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▇▇██▇████████</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>79.72835</td></tr><tr><td>train_loss</td><td>0.66803</td></tr><tr><td>val_acc</td><td>73.8665</td></tr><tr><td>val_loss</td><td>0.90026</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rural-sweep-19</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/eqpz333v' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/eqpz333v</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_153039-eqpz333v/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eh9vz2pc with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_154009-eh9vz2pc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/eh9vz2pc' target=\"_blank\">sandy-sweep-20</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/eh9vz2pc' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/eh9vz2pc</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.9374, Acc: 41.61%\nVal Loss: 1.2123, Acc: 62.61%\nEpoch 2/10\nTrain Loss: 0.9624, Acc: 71.29%\nVal Loss: 0.9207, Acc: 71.33%\nEpoch 3/10\nTrain Loss: 0.8048, Acc: 75.78%\nVal Loss: 0.9002, Acc: 72.65%\nEpoch 4/10\nTrain Loss: 0.7378, Acc: 77.64%\nVal Loss: 0.8695, Acc: 73.26%\nEpoch 5/10\nTrain Loss: 0.6903, Acc: 78.77%\nVal Loss: 0.8785, Acc: 73.78%\nEpoch 6/10\nTrain Loss: 0.6619, Acc: 79.56%\nVal Loss: 0.8391, Acc: 74.14%\nEpoch 7/10\nTrain Loss: 0.6459, Acc: 80.00%\nVal Loss: 0.8238, Acc: 74.57%\nEpoch 8/10\nTrain Loss: 0.6217, Acc: 80.50%\nVal Loss: 0.7963, Acc: 75.13%\nEpoch 9/10\nTrain Loss: 0.6067, Acc: 80.91%\nVal Loss: 0.8051, Acc: 74.92%\nEpoch 10/10\nTrain Loss: 0.5939, Acc: 81.28%\nVal Loss: 0.8182, Acc: 75.26%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇██████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▃▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>81.2814</td></tr><tr><td>train_loss</td><td>0.5939</td></tr><tr><td>val_acc</td><td>75.25535</td></tr><tr><td>val_loss</td><td>0.81824</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sandy-sweep-20</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/eh9vz2pc' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/eh9vz2pc</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_154009-eh9vz2pc/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 05iwrav9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_154224-05iwrav9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/05iwrav9' target=\"_blank\">stellar-sweep-21</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/05iwrav9' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/05iwrav9</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 2.2575, Acc: 33.58%\nVal Loss: 1.7159, Acc: 45.53%\nEpoch 2/15\nTrain Loss: 1.3144, Acc: 59.91%\nVal Loss: 1.0481, Acc: 68.16%\nEpoch 3/15\nTrain Loss: 0.9773, Acc: 70.71%\nVal Loss: 0.9763, Acc: 70.21%\nEpoch 4/15\nTrain Loss: 0.8661, Acc: 74.01%\nVal Loss: 0.9087, Acc: 71.59%\nEpoch 5/15\nTrain Loss: 0.8032, Acc: 75.73%\nVal Loss: 0.8968, Acc: 72.41%\nEpoch 6/15\nTrain Loss: 0.7693, Acc: 76.42%\nVal Loss: 0.8466, Acc: 73.13%\nEpoch 7/15\nTrain Loss: 0.7305, Acc: 77.61%\nVal Loss: 0.8583, Acc: 73.68%\nEpoch 8/15\nTrain Loss: 0.7100, Acc: 78.10%\nVal Loss: 0.8433, Acc: 74.05%\nEpoch 9/15\nTrain Loss: 0.6819, Acc: 79.05%\nVal Loss: 0.8332, Acc: 74.49%\nEpoch 10/15\nTrain Loss: 0.6672, Acc: 79.38%\nVal Loss: 0.8466, Acc: 74.78%\nEpoch 11/15\nTrain Loss: 0.6487, Acc: 79.97%\nVal Loss: 0.8449, Acc: 74.85%\nEpoch 12/15\nTrain Loss: 0.6439, Acc: 79.94%\nVal Loss: 0.8206, Acc: 74.83%\nEpoch 13/15\nTrain Loss: 0.6315, Acc: 80.19%\nVal Loss: 0.8718, Acc: 74.78%\nEpoch 14/15\nTrain Loss: 0.6157, Acc: 80.87%\nVal Loss: 0.7974, Acc: 75.26%\nEpoch 15/15\nTrain Loss: 0.6110, Acc: 80.89%\nVal Loss: 0.8392, Acc: 74.87%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇█████████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇█████████</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>80.89293</td></tr><tr><td>train_loss</td><td>0.61102</td></tr><tr><td>val_acc</td><td>74.87341</td></tr><tr><td>val_loss</td><td>0.83921</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">stellar-sweep-21</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/05iwrav9' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/05iwrav9</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_154224-05iwrav9/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ih4bxt3q with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_155219-ih4bxt3q</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/ih4bxt3q' target=\"_blank\">cosmic-sweep-22</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/ih4bxt3q' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/ih4bxt3q</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 2.5453, Acc: 27.60%\nVal Loss: 2.0865, Acc: 36.55%\nEpoch 2/10\nTrain Loss: 2.0107, Acc: 38.52%\nVal Loss: 1.6148, Acc: 48.87%\nEpoch 3/10\nTrain Loss: 1.6613, Acc: 48.91%\nVal Loss: 1.2463, Acc: 61.50%\nEpoch 4/10\nTrain Loss: 1.4642, Acc: 55.17%\nVal Loss: 1.1292, Acc: 64.97%\nEpoch 5/10\nTrain Loss: 1.3559, Acc: 58.80%\nVal Loss: 1.0711, Acc: 67.61%\nEpoch 6/10\nTrain Loss: 1.2791, Acc: 61.39%\nVal Loss: 1.0266, Acc: 68.66%\nEpoch 7/10\nTrain Loss: 1.2338, Acc: 62.81%\nVal Loss: 0.9922, Acc: 69.91%\nEpoch 8/10\nTrain Loss: 1.1852, Acc: 64.32%\nVal Loss: 1.0072, Acc: 70.10%\nEpoch 9/10\nTrain Loss: 1.1544, Acc: 65.40%\nVal Loss: 0.9742, Acc: 70.57%\nEpoch 10/10\nTrain Loss: 1.1238, Acc: 66.45%\nVal Loss: 0.9838, Acc: 70.52%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▃▅▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>66.4453</td></tr><tr><td>train_loss</td><td>1.12379</td></tr><tr><td>val_acc</td><td>70.52458</td></tr><tr><td>val_loss</td><td>0.98381</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">cosmic-sweep-22</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/ih4bxt3q' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/ih4bxt3q</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_155219-ih4bxt3q/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vihpbsf2 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_155601-vihpbsf2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vihpbsf2' target=\"_blank\">golden-sweep-23</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vihpbsf2' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vihpbsf2</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.5892, Acc: 51.98%\nVal Loss: 1.0002, Acc: 69.75%\nEpoch 2/10\nTrain Loss: 0.9114, Acc: 72.33%\nVal Loss: 0.8719, Acc: 72.41%\nEpoch 3/10\nTrain Loss: 0.8195, Acc: 75.04%\nVal Loss: 0.8747, Acc: 73.35%\nEpoch 4/10\nTrain Loss: 0.7654, Acc: 76.59%\nVal Loss: 0.8784, Acc: 72.95%\nEpoch 5/10\nTrain Loss: 0.7339, Acc: 77.55%\nVal Loss: 0.8646, Acc: 73.50%\nEpoch 6/10\nTrain Loss: 0.7078, Acc: 78.24%\nVal Loss: 0.8785, Acc: 73.62%\nEpoch 7/10\nTrain Loss: 0.6927, Acc: 78.52%\nVal Loss: 0.8622, Acc: 74.21%\nEpoch 8/10\nTrain Loss: 0.6837, Acc: 78.85%\nVal Loss: 0.8252, Acc: 74.74%\nEpoch 9/10\nTrain Loss: 0.6792, Acc: 78.83%\nVal Loss: 0.8278, Acc: 74.50%\nEpoch 10/10\nTrain Loss: 0.6512, Acc: 79.82%\nVal Loss: 0.8382, Acc: 74.60%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▅▆▆▇███</td></tr><tr><td>val_loss</td><td>█▃▃▃▃▃▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>79.82436</td></tr><tr><td>train_loss</td><td>0.65116</td></tr><tr><td>val_acc</td><td>74.60432</td></tr><tr><td>val_loss</td><td>0.83819</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">golden-sweep-23</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vihpbsf2' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/vihpbsf2</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_155601-vihpbsf2/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fq5wifyo with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_155853-fq5wifyo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/fq5wifyo' target=\"_blank\">likely-sweep-24</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/fq5wifyo' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/fq5wifyo</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.0451, Acc: 68.22%\nVal Loss: 0.9252, Acc: 71.66%\nEpoch 2/10\nTrain Loss: 0.6480, Acc: 79.72%\nVal Loss: 0.8622, Acc: 73.75%\nEpoch 3/10\nTrain Loss: 0.5954, Acc: 81.10%\nVal Loss: 0.8244, Acc: 74.69%\nEpoch 4/10\nTrain Loss: 0.5648, Acc: 81.87%\nVal Loss: 0.7952, Acc: 74.87%\nEpoch 5/10\nTrain Loss: 0.5379, Acc: 82.78%\nVal Loss: 0.7798, Acc: 75.47%\nEpoch 6/10\nTrain Loss: 0.5222, Acc: 83.10%\nVal Loss: 0.8445, Acc: 75.85%\nEpoch 7/10\nTrain Loss: 0.5151, Acc: 83.24%\nVal Loss: 0.7786, Acc: 75.55%\nEpoch 8/10\nTrain Loss: 0.4989, Acc: 83.65%\nVal Loss: 0.8201, Acc: 75.71%\nEpoch 9/10\nTrain Loss: 0.4874, Acc: 84.05%\nVal Loss: 0.8110, Acc: 76.06%\nEpoch 10/10\nTrain Loss: 0.4824, Acc: 84.12%\nVal Loss: 0.7887, Acc: 75.52%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇█▇▇█▇</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▄▁▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>84.12375</td></tr><tr><td>train_loss</td><td>0.4824</td></tr><tr><td>val_acc</td><td>75.51575</td></tr><tr><td>val_loss</td><td>0.78872</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">likely-sweep-24</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/fq5wifyo' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/fq5wifyo</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_155853-fq5wifyo/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v6uqq6tb with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_160446-v6uqq6tb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/v6uqq6tb' target=\"_blank\">neat-sweep-25</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/v6uqq6tb' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/v6uqq6tb</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 1.2023, Acc: 63.48%\nVal Loss: 0.9374, Acc: 70.98%\nEpoch 2/15\nTrain Loss: 0.7656, Acc: 76.32%\nVal Loss: 0.8799, Acc: 73.31%\nEpoch 3/15\nTrain Loss: 0.6832, Acc: 78.70%\nVal Loss: 0.8715, Acc: 74.01%\nEpoch 4/15\nTrain Loss: 0.6542, Acc: 79.45%\nVal Loss: 0.8128, Acc: 74.49%\nEpoch 5/15\nTrain Loss: 0.6223, Acc: 80.43%\nVal Loss: 0.8497, Acc: 74.86%\nEpoch 6/15\nTrain Loss: 0.6021, Acc: 80.92%\nVal Loss: 0.8030, Acc: 75.01%\nEpoch 7/15\nTrain Loss: 0.5919, Acc: 81.22%\nVal Loss: 0.8172, Acc: 75.40%\nEpoch 8/15\nTrain Loss: 0.5799, Acc: 81.53%\nVal Loss: 0.8246, Acc: 75.43%\nEpoch 9/15\nTrain Loss: 0.5694, Acc: 81.84%\nVal Loss: 0.8179, Acc: 75.72%\nEpoch 10/15\nTrain Loss: 0.5642, Acc: 81.96%\nVal Loss: 0.8048, Acc: 75.19%\nEpoch 11/15\nTrain Loss: 0.5576, Acc: 82.16%\nVal Loss: 0.7998, Acc: 75.42%\nEpoch 12/15\nTrain Loss: 0.5532, Acc: 82.27%\nVal Loss: 0.8040, Acc: 75.53%\nEpoch 13/15\nTrain Loss: 0.5416, Acc: 82.71%\nVal Loss: 0.7887, Acc: 75.92%\nEpoch 14/15\nTrain Loss: 0.5461, Acc: 82.47%\nVal Loss: 0.7734, Acc: 76.12%\nEpoch 15/15\nTrain Loss: 0.5327, Acc: 82.86%\nVal Loss: 0.7953, Acc: 75.98%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▆▅▃▄▂▃▃▃▂▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>82.86094</td></tr><tr><td>train_loss</td><td>0.53274</td></tr><tr><td>val_acc</td><td>75.97581</td></tr><tr><td>val_loss</td><td>0.79531</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">neat-sweep-25</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/v6uqq6tb' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/v6uqq6tb</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_160446-v6uqq6tb/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uo6pujdn with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_161014-uo6pujdn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/uo6pujdn' target=\"_blank\">decent-sweep-26</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/uo6pujdn' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/uo6pujdn</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 1.6826, Acc: 49.00%\nVal Loss: 0.9833, Acc: 68.59%\nEpoch 2/15\nTrain Loss: 0.8745, Acc: 72.92%\nVal Loss: 0.8375, Acc: 72.50%\nEpoch 3/15\nTrain Loss: 0.7482, Acc: 76.71%\nVal Loss: 0.8200, Acc: 74.29%\nEpoch 4/15\nTrain Loss: 0.6899, Acc: 78.46%\nVal Loss: 0.8262, Acc: 74.44%\nEpoch 5/15\nTrain Loss: 0.6451, Acc: 79.75%\nVal Loss: 0.8252, Acc: 74.69%\nEpoch 6/15\nTrain Loss: 0.6233, Acc: 80.42%\nVal Loss: 0.7637, Acc: 75.67%\nEpoch 7/15\nTrain Loss: 0.5933, Acc: 81.31%\nVal Loss: 0.8107, Acc: 75.33%\nEpoch 8/15\nTrain Loss: 0.5816, Acc: 81.61%\nVal Loss: 0.8100, Acc: 75.29%\nEpoch 9/15\nTrain Loss: 0.5680, Acc: 82.01%\nVal Loss: 0.7818, Acc: 75.72%\nEpoch 10/15\nTrain Loss: 0.5521, Acc: 82.50%\nVal Loss: 0.7805, Acc: 75.80%\nEpoch 11/15\nTrain Loss: 0.5380, Acc: 82.88%\nVal Loss: 0.8553, Acc: 75.81%\nEpoch 12/15\nTrain Loss: 0.5332, Acc: 82.96%\nVal Loss: 0.8068, Acc: 75.98%\nEpoch 13/15\nTrain Loss: 0.5382, Acc: 82.71%\nVal Loss: 0.7625, Acc: 75.95%\nEpoch 14/15\nTrain Loss: 0.5217, Acc: 83.21%\nVal Loss: 0.7591, Acc: 76.33%\nEpoch 15/15\nTrain Loss: 0.5134, Acc: 83.42%\nVal Loss: 0.7403, Acc: 76.56%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇█████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▂▃▃▂▂▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>83.41716</td></tr><tr><td>train_loss</td><td>0.51344</td></tr><tr><td>val_acc</td><td>76.55739</td></tr><tr><td>val_loss</td><td>0.7403</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">decent-sweep-26</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/uo6pujdn' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/uo6pujdn</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_161014-uo6pujdn/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 04smivhe with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_161330-04smivhe</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/04smivhe' target=\"_blank\">unique-sweep-27</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/04smivhe' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/04smivhe</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 2.5109, Acc: 28.89%\nVal Loss: 2.0238, Acc: 38.10%\nEpoch 2/10\nTrain Loss: 1.5624, Acc: 50.93%\nVal Loss: 1.1102, Acc: 65.64%\nEpoch 3/10\nTrain Loss: 1.0185, Acc: 68.82%\nVal Loss: 0.9203, Acc: 70.50%\nEpoch 4/10\nTrain Loss: 0.8715, Acc: 73.00%\nVal Loss: 0.8712, Acc: 72.10%\nEpoch 5/10\nTrain Loss: 0.7973, Acc: 75.35%\nVal Loss: 0.8537, Acc: 72.46%\nEpoch 6/10\nTrain Loss: 0.7430, Acc: 76.99%\nVal Loss: 0.8379, Acc: 73.87%\nEpoch 7/10\nTrain Loss: 0.7068, Acc: 78.18%\nVal Loss: 0.8035, Acc: 74.40%\nEpoch 8/10\nTrain Loss: 0.6847, Acc: 78.60%\nVal Loss: 0.8081, Acc: 74.29%\nEpoch 9/10\nTrain Loss: 0.6562, Acc: 79.48%\nVal Loss: 0.8043, Acc: 74.90%\nEpoch 10/10\nTrain Loss: 0.6404, Acc: 80.00%\nVal Loss: 0.8069, Acc: 75.12%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▄▆▇▇█████</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>80.0048</td></tr><tr><td>train_loss</td><td>0.64039</td></tr><tr><td>val_acc</td><td>75.11646</td></tr><tr><td>val_loss</td><td>0.80689</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">unique-sweep-27</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/04smivhe' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/04smivhe</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_161330-04smivhe/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z4a2zz82 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_161627-z4a2zz82</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/z4a2zz82' target=\"_blank\">lemon-sweep-28</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/z4a2zz82' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/z4a2zz82</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 1.3089, Acc: 60.64%\nVal Loss: 0.9456, Acc: 71.43%\nEpoch 2/15\nTrain Loss: 0.7817, Acc: 76.15%\nVal Loss: 0.8573, Acc: 73.20%\nEpoch 3/15\nTrain Loss: 0.7002, Acc: 78.28%\nVal Loss: 0.8484, Acc: 73.97%\nEpoch 4/15\nTrain Loss: 0.6577, Acc: 79.48%\nVal Loss: 0.8318, Acc: 74.52%\nEpoch 5/15\nTrain Loss: 0.6275, Acc: 80.33%\nVal Loss: 0.8067, Acc: 74.87%\nEpoch 6/15\nTrain Loss: 0.6082, Acc: 80.82%\nVal Loss: 0.7863, Acc: 75.19%\nEpoch 7/15\nTrain Loss: 0.5930, Acc: 81.26%\nVal Loss: 0.7977, Acc: 75.16%\nEpoch 8/15\nTrain Loss: 0.5812, Acc: 81.62%\nVal Loss: 0.7925, Acc: 75.02%\nEpoch 9/15\nTrain Loss: 0.5642, Acc: 82.12%\nVal Loss: 0.8068, Acc: 75.41%\nEpoch 10/15\nTrain Loss: 0.5582, Acc: 82.19%\nVal Loss: 0.8024, Acc: 75.83%\nEpoch 11/15\nTrain Loss: 0.5597, Acc: 82.06%\nVal Loss: 0.7603, Acc: 75.66%\nEpoch 12/15\nTrain Loss: 0.5426, Acc: 82.60%\nVal Loss: 0.8041, Acc: 75.50%\nEpoch 13/15\nTrain Loss: 0.5383, Acc: 82.76%\nVal Loss: 0.8117, Acc: 75.97%\nEpoch 14/15\nTrain Loss: 0.5326, Acc: 82.88%\nVal Loss: 0.8164, Acc: 75.93%\nEpoch 15/15\nTrain Loss: 0.5284, Acc: 82.96%\nVal Loss: 0.8089, Acc: 75.47%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▇▇▇▇██▇██▇</td></tr><tr><td>val_loss</td><td>█▅▄▄▃▂▂▂▃▃▁▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>82.96027</td></tr><tr><td>train_loss</td><td>0.52844</td></tr><tr><td>val_acc</td><td>75.46946</td></tr><tr><td>val_loss</td><td>0.80888</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lemon-sweep-28</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/z4a2zz82' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/z4a2zz82</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_161627-z4a2zz82/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2yew837r with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_162445-2yew837r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/2yew837r' target=\"_blank\">happy-sweep-29</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/2yew837r' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/2yew837r</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nTrain Loss: 1.1083, Acc: 67.11%\nVal Loss: 0.9629, Acc: 70.57%\nEpoch 2/15\nTrain Loss: 0.6854, Acc: 79.01%\nVal Loss: 0.8795, Acc: 72.39%\nEpoch 3/15\nTrain Loss: 0.6285, Acc: 80.40%\nVal Loss: 0.8690, Acc: 73.82%\nEpoch 4/15\nTrain Loss: 0.5906, Acc: 81.47%\nVal Loss: 0.8232, Acc: 74.25%\nEpoch 5/15\nTrain Loss: 0.5742, Acc: 81.76%\nVal Loss: 0.8182, Acc: 73.68%\nEpoch 6/15\nTrain Loss: 0.5536, Acc: 82.38%\nVal Loss: 0.8186, Acc: 74.91%\nEpoch 7/15\nTrain Loss: 0.5413, Acc: 82.65%\nVal Loss: 0.8081, Acc: 74.86%\nEpoch 8/15\nTrain Loss: 0.5237, Acc: 83.29%\nVal Loss: 0.8119, Acc: 74.97%\nEpoch 9/15\nTrain Loss: 0.5111, Acc: 83.60%\nVal Loss: 0.7972, Acc: 75.36%\nEpoch 10/15\nTrain Loss: 0.5088, Acc: 83.53%\nVal Loss: 0.7974, Acc: 75.48%\nEpoch 11/15\nTrain Loss: 0.5022, Acc: 83.76%\nVal Loss: 0.8097, Acc: 75.19%\nEpoch 12/15\nTrain Loss: 0.4964, Acc: 83.88%\nVal Loss: 0.8004, Acc: 75.36%\nEpoch 13/15\nTrain Loss: 0.4877, Acc: 84.08%\nVal Loss: 0.8045, Acc: 75.42%\nEpoch 14/15\nTrain Loss: 0.4861, Acc: 84.06%\nVal Loss: 0.8092, Acc: 75.04%\nEpoch 15/15\nTrain Loss: 0.4775, Acc: 84.41%\nVal Loss: 0.7950, Acc: 75.48%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▅▇▇▇█████▇█</td></tr><tr><td>val_loss</td><td>█▅▄▂▂▂▂▂▁▁▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>84.4082</td></tr><tr><td>train_loss</td><td>0.47749</td></tr><tr><td>val_acc</td><td>75.47814</td></tr><tr><td>val_loss</td><td>0.79498</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">happy-sweep-29</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/2yew837r' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/2yew837r</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_162445-2yew837r/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wbrsydns with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: concat\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'dakshina-transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_163228-wbrsydns</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/wbrsydns' target=\"_blank\">lunar-sweep-30</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/sweeps/64q660zv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/wbrsydns' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/wbrsydns</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.5142, Acc: 54.02%\nVal Loss: 1.0001, Acc: 68.74%\nEpoch 2/10\nTrain Loss: 0.8397, Acc: 74.15%\nVal Loss: 0.8635, Acc: 72.71%\nEpoch 3/10\nTrain Loss: 0.7281, Acc: 77.54%\nVal Loss: 0.8369, Acc: 73.72%\nEpoch 4/10\nTrain Loss: 0.6878, Acc: 78.64%\nVal Loss: 0.8221, Acc: 74.04%\nEpoch 5/10\nTrain Loss: 0.6428, Acc: 80.01%\nVal Loss: 0.8310, Acc: 74.59%\nEpoch 6/10\nTrain Loss: 0.6204, Acc: 80.64%\nVal Loss: 0.8199, Acc: 74.61%\nEpoch 7/10\nTrain Loss: 0.6094, Acc: 80.95%\nVal Loss: 0.8108, Acc: 74.48%\nEpoch 8/10\nTrain Loss: 0.5889, Acc: 81.50%\nVal Loss: 0.8158, Acc: 75.18%\nEpoch 9/10\nTrain Loss: 0.5622, Acc: 82.34%\nVal Loss: 0.8262, Acc: 75.21%\nEpoch 10/10\nTrain Loss: 0.5605, Acc: 82.30%\nVal Loss: 0.8074, Acc: 75.14%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>82.30252</td></tr><tr><td>train_loss</td><td>0.56055</td></tr><tr><td>val_acc</td><td>75.13961</td></tr><tr><td>val_loss</td><td>0.80738</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lunar-sweep-30</strong> at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/wbrsydns' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention/runs/wbrsydns</a><br> View project at: <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-transliteration-attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_163228-wbrsydns/logs</code>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nimport random\nimport wandb\n\n# =======================\n# Best Configuration\n# =======================\nbest_config = {\n    'embedding_dim': 256,\n    'hidden_dim': 256,\n    'enc_layers': 2,\n    'dec_layers': 2,\n    'cell_type': 'LSTM',\n    'dropout': 0.5,\n    'epochs': 15,\n    'beam_size': 5,\n    'attention_type': 'concat',\n    'batch_size': 256,\n    'learning_rate': 0.001\n}\n\n# =======================\n# Vocabulary\n# =======================\nclass Vocab:\n    def __init__(self):\n        self.char2idx = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2}\n        self.idx2char = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\"}\n        self.size = 3\n\n    def build(self, texts):\n        for text in texts:\n            for char in text:\n                if char not in self.char2idx:\n                    self.char2idx[char] = self.size\n                    self.idx2char[self.size] = char\n                    self.size += 1\n\n    def encode(self, text):\n        return [self.char2idx[c] for c in text]\n\n    def decode(self, idxs):\n        return ''.join([self.idx2char[i] for i in idxs if i not in [0, 1, 2]])\n\n# =======================\n# Dataset\n# =======================\nclass TransliterationDataset(Dataset):\n    def __init__(self, filepath, inp_vocab, out_vocab, is_test=False):\n        self.pairs = []\n        with open(filepath, encoding='utf-8') as f:\n            for line in f:\n                fields = line.strip().split('\\t')\n                if len(fields) < 2:\n                    continue\n                lat, dev = fields[0], fields[1]\n                self.pairs.append((lat, dev))\n        if not is_test:\n            inp_vocab.build([p[0] for p in self.pairs])\n            out_vocab.build([p[1] for p in self.pairs])\n        self.inp_vocab = inp_vocab\n        self.out_vocab = out_vocab\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        lat, dev = self.pairs[idx]\n        x = self.inp_vocab.encode(lat)\n        if self.is_test:\n            return torch.tensor(x), lat, dev\n        y = [self.out_vocab.char2idx[\"<sos>\"]] + self.out_vocab.encode(dev) + [self.out_vocab.char2idx[\"<eos>\"]]\n        return torch.tensor(x), torch.tensor(y), lat, dev\n\ndef collate_fn(batch):\n    if len(batch[0]) == 3:  # Test batch\n        x_batch, lat, dev = zip(*batch)\n        x_lens = [len(x) for x in x_batch]\n        x_pad = nn.utils.rnn.pad_sequence(x_batch, batch_first=True, padding_value=0)\n        return x_pad, lat, dev, torch.tensor(x_lens)\n    else:  # Train/val batch\n        x_batch, y_batch, lat, dev = zip(*batch)\n        x_lens = [len(x) for x in x_batch]\n        y_lens = [len(y) for y in y_batch]\n        x_pad = nn.utils.rnn.pad_sequence(x_batch, batch_first=True, padding_value=0)\n        y_pad = nn.utils.rnn.pad_sequence(y_batch, batch_first=True, padding_value=0)\n        return x_pad, y_pad, torch.tensor(x_lens), torch.tensor(y_lens), lat, dev\n\n# =======================\n# Model Components\n# =======================\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        rnn_class = {\"GRU\": nn.GRU, \"LSTM\": nn.LSTM, \"RNN\": nn.RNN}[cell_type]\n        self.rnn = rnn_class(emb_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n\n    def forward(self, x, lengths):\n        embedded = self.embedding(x)\n        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n        outputs, hidden = self.rnn(packed)\n        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n        return outputs, hidden\n\nclass Attention(nn.Module):\n    def __init__(self, hidden_dim, attention_type='general'):\n        super().__init__()\n        self.attention_type = attention_type\n        if attention_type == 'general':\n            self.attn = nn.Linear(hidden_dim, hidden_dim)\n        elif attention_type == 'concat':\n            self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n            self.v = nn.Linear(hidden_dim, 1, bias=False)\n\n    def forward(self, hidden, encoder_outputs, mask=None):\n        batch_size, src_len, hidden_dim = encoder_outputs.size()\n        \n        if self.attention_type == 'general':\n            energy = torch.bmm(encoder_outputs, self.attn(hidden).unsqueeze(2)).squeeze(2)\n        elif self.attention_type == 'concat':\n            hidden_expanded = hidden.unsqueeze(1).repeat(1, src_len, 1)\n            concat = torch.cat((hidden_expanded, encoder_outputs), dim=2)\n            energy = self.v(torch.tanh(self.attn(concat))).squeeze(2)\n        else:  # dot\n            energy = torch.bmm(encoder_outputs, hidden.unsqueeze(2)).squeeze(2)\n        \n        if mask is not None:\n            energy = energy.masked_fill(mask == 0, -1e10)\n        attention_weights = F.softmax(energy, dim=1)\n        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n        return context, attention_weights\n\nclass Decoder(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers, cell_type, dropout, attention_type):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        rnn_class = {\"GRU\": nn.GRU, \"LSTM\": nn.LSTM, \"RNN\": nn.RNN}[cell_type]\n        self.rnn = rnn_class(emb_dim + hidden_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n        self.attention = Attention(hidden_dim, attention_type)\n        self.out = nn.Linear(hidden_dim * 2, vocab_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input_token, hidden, encoder_outputs, mask=None):\n        if isinstance(hidden, tuple):  # LSTM\n            attn_hidden = hidden[0][-1]\n        else:  # GRU/RNN\n            attn_hidden = hidden[-1]\n        \n        context, _ = self.attention(attn_hidden, encoder_outputs, mask)\n        embedded = self.embedding(input_token)\n        rnn_input = torch.cat((embedded, context), dim=1).unsqueeze(1)\n        output, hidden = self.rnn(rnn_input, hidden)\n        \n        if isinstance(hidden, tuple):\n            output_hidden = hidden[0][-1]\n        else:\n            output_hidden = hidden[-1]\n        \n        output = torch.cat((output_hidden, context), dim=1)\n        output = self.dropout(output)\n        prediction = self.out(output)\n        return prediction, hidden, None\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def create_mask(self, src_lens, max_len):\n        batch_size = len(src_lens)\n        mask = torch.zeros(batch_size, max_len, device=self.device)\n        for i, length in enumerate(src_lens):\n            mask[i, :length] = 1\n        return mask\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        src_data, src_lens = src\n        encoder_outputs, enc_hidden = self.encoder(src_data, src_lens)\n        batch_size, trg_len = trg.size()\n        vocab_size = self.decoder.out.out_features\n        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n        \n        src_len = encoder_outputs.size(1)\n        mask = self.create_mask(src_lens, src_len)\n\n        if isinstance(enc_hidden, tuple):\n            dec_hidden = enc_hidden\n        else:\n            dec_hidden = enc_hidden\n\n        input_token = trg[:, 0]\n        for t in range(1, trg_len):\n            output, dec_hidden, _ = self.decoder(input_token, dec_hidden, encoder_outputs, mask)\n            outputs[:, t] = output\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input_token = trg[:, t] if teacher_force else top1\n            \n        return outputs\n\n    def predict(self, src, src_lens, max_len=30):\n        self.eval()\n        with torch.no_grad():\n            encoder_outputs, enc_hidden = self.encoder(src, src_lens)\n            src_len = encoder_outputs.size(1)\n            mask = self.create_mask(src_lens.tolist(), src_len)\n            \n            if isinstance(enc_hidden, tuple):\n                dec_hidden = enc_hidden\n            else:\n                dec_hidden = enc_hidden\n            \n            input_token = torch.tensor([1], device=self.device)\n            output_seq = []\n            for _ in range(max_len):\n                output, dec_hidden, _ = self.decoder(input_token, dec_hidden, encoder_outputs, mask)\n                top1 = output.argmax(1)\n                if top1.item() == 2:\n                    break\n                output_seq.append(top1.item())\n                input_token = top1\n        return output_seq\n\n# =======================\n# Training and Evaluation\n# =======================\ndef train(model, loader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    total_correct = 0\n    total_tokens = 0\n    \n    for batch in loader:\n        src, trg, src_lens, _, _, _ = batch\n        src, trg = src.to(device), trg.to(device)\n        optimizer.zero_grad()\n        output = model((src, src_lens), trg)\n        \n        # Calculate loss\n        output_dim = output.shape[-1]\n        loss = criterion(output[:, 1:].reshape(-1, output_dim), trg[:, 1:].reshape(-1))\n        loss.backward()\n        optimizer.step()\n        \n        # Calculate accuracy\n        pred = output.argmax(dim=2)\n        mask = (trg[:, 1:] != 0)\n        correct = ((pred[:, 1:] == trg[:, 1:]) & mask).sum().item()\n        total_correct += correct\n        total_tokens += mask.sum().item()\n        total_loss += loss.item()\n    \n    avg_loss = total_loss / len(loader)\n    accuracy = (total_correct / total_tokens) * 100 if total_tokens > 0 else 0\n    return avg_loss, accuracy\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    total_correct = 0\n    total_tokens = 0\n    \n    with torch.no_grad():\n        for batch in loader:\n            src, trg, src_lens, _, _, _ = batch\n            src, trg = src.to(device), trg.to(device)\n            output = model((src, src_lens), trg, teacher_forcing_ratio=0)\n            \n            # Calculate loss\n            output_dim = output.shape[-1]\n            loss = criterion(output[:, 1:].reshape(-1, output_dim), trg[:, 1:].reshape(-1))\n            \n            # Calculate accuracy\n            pred = output.argmax(dim=2)\n            mask = (trg[:, 1:] != 0)\n            correct = ((pred[:, 1:] == trg[:, 1:]) & mask).sum().item()\n            total_correct += correct\n            total_tokens += mask.sum().item()\n            total_loss += loss.item()\n    \n    avg_loss = total_loss / len(loader)\n    accuracy = (total_correct / total_tokens) * 100 if total_tokens > 0 else 0\n    return avg_loss, accuracy\n\n# =======================\n# Main Execution\n# =======================\ndef main():\n    wandb.init(config=best_config, project=\"dakshina-translit\")\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Initialize vocabularies\n    inp_vocab = Vocab()\n    out_vocab = Vocab()\n\n    # Load datasets\n    train_data = TransliterationDataset(\"/kaggle/input/devnagiridata/hi.translit.sampled.train.tsv\", inp_vocab, out_vocab)\n    dev_data = TransliterationDataset(\"/kaggle/input/devnagiridata/hi.translit.sampled.dev.tsv\", inp_vocab, out_vocab)\n    test_data = TransliterationDataset(\"/kaggle/input/devnagiridata/hi.translit.sampled.test.tsv\", inp_vocab, out_vocab, is_test=True)\n\n    # Create data loaders\n    train_loader = DataLoader(train_data, batch_size=best_config['batch_size'], \n                            shuffle=True, collate_fn=collate_fn)\n    dev_loader = DataLoader(dev_data, batch_size=best_config['batch_size'],\n                          shuffle=False, collate_fn=collate_fn)\n    test_loader = DataLoader(test_data, batch_size=1, shuffle=False, collate_fn=collate_fn)\n\n    # Initialize model\n    encoder = Encoder(inp_vocab.size, best_config['embedding_dim'], \n                     best_config['hidden_dim'], best_config['enc_layers'], \n                     best_config['cell_type'], best_config['dropout'])\n    \n    decoder = Decoder(out_vocab.size, best_config['embedding_dim'],\n                     best_config['hidden_dim'], best_config['dec_layers'],\n                     best_config['cell_type'], best_config['dropout'],\n                     best_config['attention_type'])\n    \n    model = Seq2Seq(encoder, decoder, device).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=best_config['learning_rate'])\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    # Training loop\n    best_val_loss = float('inf')\n    for epoch in range(best_config['epochs']):\n        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = evaluate(model, dev_loader, criterion, device)\n        \n        print(f\"\\nEpoch {epoch+1}/{best_config['epochs']}\")\n        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_loss\": train_loss,\n            \"train_acc\": train_acc,\n            \"val_loss\": val_loss,\n            \"val_acc\": val_acc\n        })\n        \n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), \"best_model.pth\")\n            print(\"Best model saved!\")\n\n    # Test evaluation\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n    model.eval()\n    \n    total_correct = 0\n    total_samples = 0\n    predictions = []\n    \n    with torch.no_grad():\n        for batch in test_loader:\n            src, lat, dev, src_lens = batch\n            src = src.to(device)\n            pred_ids = model.predict(src, src_lens)\n            pred_str = out_vocab.decode(pred_ids)\n            true_str = dev[0]\n            \n            predictions.append({\n                'input': lat[0],\n                'true': true_str,\n                'pred': pred_str\n            })\n            \n            if pred_str == true_str:\n                total_correct += 1\n            total_samples += 1\n\n    # Calculate accuracy\n    accuracy = 100 * total_correct / total_samples\n    print(f\"\\nTest Accuracy: {accuracy:.2f}%\")\n    wandb.log({\"test_acc\": accuracy})\n\n     # Create and log a table of predictions\n    table = wandb.Table(columns=[\"Input\", \"True\", \"Predicted\"])\n    for p in predictions[:20]:  # Log first 20 predictions\n        table.add_data(p['input'], p['true'], p['pred'])\n    \n    wandb.log({\n        \"predictions\": table,\n        \"test_accuracy\": accuracy\n    })\n\n    \n    # Save predictions\n    with open(\"test_predictions.txt\", \"w\", encoding=\"utf-8\") as f:\n        f.write(f\"Test Accuracy: {accuracy:.2f}%\\n\\n\")\n        for p in predictions[:20]:\n            f.write(f\"Input: {p['input']}\\n\")\n            f.write(f\"True: {p['true']}\\n\")\n            f.write(f\"Pred: {p['pred']}\\n\\n\")\n    \n    # Print random samples\n    print(\"\\nRandom Samples:\")\n    samples = random.sample(predictions, 5)\n    for sample in samples:\n        print(f\"Input: {sample['input']}\")\n        print(f\"True: {sample['true']}\")\n        print(f\"Pred: {sample['pred']}\\n\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:26:00.438223Z","iopub.execute_input":"2025-05-19T18:26:00.438816Z","iopub.status.idle":"2025-05-19T18:30:19.354782Z","shell.execute_reply.started":"2025-05-19T18:26:00.438778Z","shell.execute_reply":"2025-05-19T18:30:19.354011Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanglesh_dlass3\u001b[0m (\u001b[33mmanglesh_dl_ass3\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_182600-3pgstmly</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/manglesh_dl_ass3/dakshina-translit/runs/3pgstmly' target=\"_blank\">frosty-wildflower-34</a></strong> to <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-translit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-translit' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-translit</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/manglesh_dl_ass3/dakshina-translit/runs/3pgstmly' target=\"_blank\">https://wandb.ai/manglesh_dl_ass3/dakshina-translit/runs/3pgstmly</a>"},"metadata":{}},{"name":"stdout","text":"\nEpoch 1/15\nTrain Loss: 1.6700 | Train Acc: 49.26%\nVal Loss: 0.9560 | Val Acc: 69.54%\nBest model saved!\n\nEpoch 2/15\nTrain Loss: 0.8696 | Train Acc: 73.11%\nVal Loss: 0.9008 | Val Acc: 71.14%\nBest model saved!\n\nEpoch 3/15\nTrain Loss: 0.7541 | Train Acc: 76.55%\nVal Loss: 0.8106 | Val Acc: 73.87%\nBest model saved!\n\nEpoch 4/15\nTrain Loss: 0.6842 | Train Acc: 78.64%\nVal Loss: 0.8309 | Val Acc: 74.67%\n\nEpoch 5/15\nTrain Loss: 0.6603 | Train Acc: 79.25%\nVal Loss: 0.8221 | Val Acc: 75.44%\n\nEpoch 6/15\nTrain Loss: 0.6305 | Train Acc: 80.20%\nVal Loss: 0.7608 | Val Acc: 75.27%\nBest model saved!\n\nEpoch 7/15\nTrain Loss: 0.6054 | Train Acc: 80.90%\nVal Loss: 0.7964 | Val Acc: 75.49%\n\nEpoch 8/15\nTrain Loss: 0.5982 | Train Acc: 81.02%\nVal Loss: 0.8013 | Val Acc: 75.42%\n\nEpoch 9/15\nTrain Loss: 0.5822 | Train Acc: 81.49%\nVal Loss: 0.7886 | Val Acc: 75.25%\n\nEpoch 10/15\nTrain Loss: 0.5663 | Train Acc: 81.96%\nVal Loss: 0.7844 | Val Acc: 75.90%\n\nEpoch 11/15\nTrain Loss: 0.5470 | Train Acc: 82.60%\nVal Loss: 0.7712 | Val Acc: 75.82%\n\nEpoch 12/15\nTrain Loss: 0.5418 | Train Acc: 82.67%\nVal Loss: 0.7733 | Val Acc: 76.17%\n\nEpoch 13/15\nTrain Loss: 0.5286 | Train Acc: 83.13%\nVal Loss: 0.8127 | Val Acc: 75.94%\n\nEpoch 14/15\nTrain Loss: 0.5188 | Train Acc: 83.38%\nVal Loss: 0.7591 | Val Acc: 76.43%\nBest model saved!\n\nEpoch 15/15\nTrain Loss: 0.5177 | Train Acc: 83.30%\nVal Loss: 0.8155 | Val Acc: 76.18%\n\nTest Accuracy: 43.38%\n\nRandom Samples:\nInput: कोच्चि\nTrue: kochi\nPred: kochchi\n\nInput: जतरा\nTrue: jatara\nPred: jatra\n\nInput: लैंगडन\nTrue: lengdan\nPred: langdon\n\nInput: सभ्यता\nTrue: sabhyata\nPred: sabhyata\n\nInput: काजी\nTrue: kaaji\nPred: kaji\n\n","output_type":"stream"}],"execution_count":12}]}